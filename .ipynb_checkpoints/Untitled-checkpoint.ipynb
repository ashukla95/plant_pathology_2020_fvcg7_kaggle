{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Dense, Flatten,Dropout,Conv2D, ReLU, MaxPooling2D,\n",
    "                                     Activation, BatchNormalization, GlobalAveragePooling2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"images/\"\n",
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_id\"] = train_df.image_id.apply(lambda x: x+\".jpg\")\n",
    "test_df[\"image_id\"] = test_df.image_id.apply(lambda x: x+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(df, val_ratio=0.2):\n",
    "    val_rows = (np.random.rand(int(val_ratio*df.shape[0]))*df.shape[0]).astype(int)\n",
    "    val_df = df.iloc[val_rows]\n",
    "    train_df.drop(val_rows, axis=0, inplace=True)\n",
    "    val_df = val_df.reset_index().drop([\"index\"], axis=1)\n",
    "    df = df.reset_index().drop([\"index\"], axis=1)\n",
    "    int_dict = {\n",
    "        \"healthy\": np.float32,\n",
    "        \"multiple_diseases\": np.float32,\n",
    "        \"rust\": np.float32,\n",
    "        \"scab\": np.float32\n",
    "    }\n",
    "    df = df.astype(int_dict)\n",
    "    val_df = val_df.astype(int_dict)\n",
    "    return df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_val_split(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  healthy  multiple_diseases  rust  scab\n",
       "0  Train_0.jpg      0.0                0.0   0.0   1.0\n",
       "1  Train_1.jpg      0.0                1.0   0.0   0.0\n",
       "2  Train_2.jpg      1.0                0.0   0.0   0.0\n",
       "3  Train_3.jpg      0.0                0.0   1.0   0.0\n",
       "4  Train_4.jpg      1.0                0.0   0.0   0.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_560.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1303.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_1583.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_481.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_497.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  healthy  multiple_diseases  rust  scab\n",
       "0   Train_560.jpg      0.0                0.0   1.0   0.0\n",
       "1  Train_1303.jpg      0.0                0.0   0.0   1.0\n",
       "2  Train_1583.jpg      1.0                0.0   0.0   0.0\n",
       "3   Train_481.jpg      0.0                0.0   1.0   0.0\n",
       "4   Train_497.jpg      0.0                0.0   1.0   0.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_df.keys().drop(\"image_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['healthy', 'multiple_diseases', 'rust', 'scab']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_freq(df, labels=labels):\n",
    "    for col in labels:\n",
    "        print(f'{col}: {sum(df[col])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy: 424.0\n",
      "multiple_diseases: 78.0\n",
      "rust: 506.0\n",
      "scab: 483.0\n"
     ]
    }
   ],
   "source": [
    "print_class_freq(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy: 99.0\n",
      "multiple_diseases: 14.0\n",
      "rust: 132.0\n",
      "scab: 119.0\n"
     ]
    }
   ],
   "source": [
    "print_class_freq(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_SMOTE(train_df=train_df):\n",
    "    X_train = []\n",
    "    for image in train_df[\"image_id\"]:\n",
    "        load_images = load_img(IMAGE_PATH+image, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        img_arr = img_to_array(load_images)\n",
    "        X_train.append(img_arr)\n",
    "    y_train = train_df.loc[:, \"healthy\":].values\n",
    "    X_train = np.asarray(X_train)\n",
    "    sm = SMOTE(random_state =45)\n",
    "    X_train, y_train = sm.fit_resample(X_train.reshape((-1, IMAGE_SIZE*IMAGE_SIZE*3)), y_train)\n",
    "    X_train.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = C_SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2024, 67500)\n",
      "(2024, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2024, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_generator(test_df=test_df, valid_df=val_df, train_df=train_df, image_dir=IMAGE_PATH,\n",
    "                       x_col=\"image_id\", y_cols=labels, sample_size=100, batch_size=32, seed=45):\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=sample_size,\n",
    "        shuffle=True,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "    )\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "    \n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True\n",
    "    )\n",
    "    image_generator.fit(data_sample)\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        seed=seed,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "    )\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        class_mode=None,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "    )\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator():\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True\n",
    "    )\n",
    "    return image_generator.flow(X_train, y_train, batch_size=32, shuffle=False, seed=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1491 validated image filenames.\n",
      "Found 364 validated image filenames.\n",
      "Found 1821 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_train_generator()\n",
    "valid_generator, test_generator = get_valid_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "\n",
    "    N = labels.shape[0]\n",
    "    \n",
    "    positive_frequencies = np.mean(labels, axis=0)\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "\n",
    "    return positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(train_generator.y)\n",
    "\n",
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.75, 0.75, 0.75])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25, 0.25, 0.25])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "    \n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        \n",
    "        # initialize loss to zero\n",
    "        loss = 0.0\n",
    "        \n",
    "\n",
    "        for i in range(len(pos_weights)):\n",
    "            # for each class, add average weighted loss for that class \n",
    "            loss += K.mean(-(pos_weights[i]*y_true[:, i]*K.log(y_pred[:, i]+epsilon)\n",
    "                             + neg_weights[i]*(1-y_true[:, i])*K.log((1-y_pred[:, i])+epsilon)))\n",
    "        return loss\n",
    "    \n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS=64\n",
    "model = Sequential()\n",
    "model.add(InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\")),\n",
    "for i in range(5):\n",
    "    model.add(Conv2D(filters=FILTERS, kernel_size=3, padding='SAME', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv2D(filters=FILTERS, kernel_size=3, padding='SAME'))\n",
    "    model.add(ReLU())\n",
    "    if i != 4:\n",
    "        model.add(Conv2D(filters=FILTERS, kernel_size=5, padding='SAME', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "        model.add(ReLU())\n",
    "    FILTERS*=2\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_1059 (Conv2D)         (None, 3, 3, 64)          1179712   \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1060 (Conv2D)         (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1061 (Conv2D)         (None, 3, 3, 64)          102464    \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1062 (Conv2D)         (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1063 (Conv2D)         (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1064 (Conv2D)         (None, 3, 3, 128)         409728    \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1065 (Conv2D)         (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1066 (Conv2D)         (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1067 (Conv2D)         (None, 3, 3, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1068 (Conv2D)         (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1069 (Conv2D)         (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1070 (Conv2D)         (None, 3, 3, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1071 (Conv2D)         (None, 3, 3, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1072 (Conv2D)         (None, 3, 3, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1047 (Ba (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1048 (Ba (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 50,549,492\n",
      "Trainable params: 50,512,980\n",
      "Non-trainable params: 36,512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor = 0.5,\n",
    "    patience=10,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20\n",
    ")\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_filepath,\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_acc',\n",
    "#     mode='max',\n",
    "#     verbose=1,\n",
    "#     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 11 steps\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "history = model.fit(train_generator, \n",
    "                   steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                   validation_data = valid_generator,\n",
    "                   validation_steps=STEP_SIZE_VALID,\n",
    "                   callbacks=[lr], epochs=200\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict_generator(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test['healthy'] = test_preds[:, 0]\n",
    "test['multiple_diseases'] = test_preds[:, 1]\n",
    "test['rust'] = test_preds[:, 2]\n",
    "test['scab'] = test_preds[:, 3]\n",
    "test.head()\n",
    "test.to_csv(\"res50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
