{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential, load_model, Input\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "IMAGE_PATH = \"images/\"\n",
    "IMAGE_SIZE = 80\n",
    "FILTERS=64\n",
    "EPOCHS=300\n",
    "REGULARIZER_VALUE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df[train_df.keys().drop(\"image_id\")]\n",
    "test_ids = test_df[\"image_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = train_df.shape[0]\n",
    "test_len = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.empty((train_len, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "for i in tqdm(range(train_len)):\n",
    "    train_images[i] = np.asarray(Image.open(IMAGE_PATH+\"Train_{}.jpg\".format(i)).resize((IMAGE_SIZE, IMAGE_SIZE)))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.empty((test_len, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "for i in tqdm(range(test_len)):\n",
    "    test_images[i] = np.asarray(Image.open(IMAGE_PATH+\"Test_{}.jpg\".format(i)).resize((IMAGE_SIZE, IMAGE_SIZE)))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(patience=15, verbose=1)\n",
    "es = EarlyStopping(patience=35, restore_best_weights=True, verbose=1)\n",
    "mc = ModelCheckpoint('model.hdf5', save_best_only=True, verbose=0)\n",
    "model = Sequential()\n",
    "for i in range(5):\n",
    "    model.add(Conv2D(filters=FILTERS, kernel_size=3, padding='SAME', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(filters=FILTERS, kernel_size=3, padding='SAME'))\n",
    "    model.add(LeakyReLU())\n",
    "    if i < 4:\n",
    "        model.add(Conv2D(filters=FILTERS, kernel_size=5, padding='SAME'))\n",
    "        model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    FILTERS *= 2\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train_images, target.to_numpy(), test_size = 0.2, random_state=64378538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagegen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "history = model.fit_generator(\n",
    "    imagegen.flow(x_train, y_train, batch_size=32),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=x_train.shape[0] // 32,\n",
    "    verbose=1,\n",
    "    callbacks=[rlr, es, mc],\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "# load best model\n",
    "model = load_model('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "h = history.history\n",
    "print(h.keys())\n",
    "offset = 5\n",
    "epochs = range(offset, len(h['loss']))\n",
    "\n",
    "plt.figure(1, figsize=(20, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(epochs, h['loss'][offset:], label='train')\n",
    "plt.plot(epochs, h['val_loss'][offset:], label='val')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(h[f'accuracy'], label='train')\n",
    "plt.plot(h[f'val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred_test = model.predict(x_val)\n",
    "roc_sum = 0\n",
    "for i in range(4):\n",
    "    score = roc_auc_score(y_val[:, i], pred_test[:, i])\n",
    "    roc_sum += score\n",
    "    print(f'{score:.3f}')\n",
    "\n",
    "roc_sum /= 4\n",
    "print(f'totally:{roc_sum:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_images)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['image_id'] = test_ids\n",
    "res['healthy'] = pred[:, 0]\n",
    "res['multiple_diseases'] = pred[:, 1]\n",
    "res['rust'] = pred[:, 2]\n",
    "res['scab'] = pred[:, 3]\n",
    "res.to_csv('submission_id_{}.csv'.format(datetime.datetime.fromtimestamp), index=False)\n",
    "res.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
