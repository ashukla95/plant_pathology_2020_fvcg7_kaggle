{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random, re, math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import ResNet152V2, InceptionResNetV2, InceptionV3, Xception, VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO=tf.data.experimental.AUTOTUNE\n",
    "IMAGE_PATH = \"images/\"\n",
    "nb_classes = 4\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "SEED = 123\n",
    "IMAGE_SIZE = 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "train_paths = train_df.image_id.apply(lambda x: \"\".join([IMAGE_PATH, x, \".jpg\"])).values\n",
    "test_paths = test_df.image_id.apply(lambda x: \"\".join([IMAGE_PATH, x, \".jpg\"])).values\n",
    "train_labels = train_df.loc[:, \"healthy\":].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32)/255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(image, label=None, seed = 69):\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "    image = tf.image.random_flip_up_down(image, seed=seed)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths, train_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .map(data_augment, num_parallel_calls=AUTO)\n",
    "    .repeat()\n",
    "    .shuffle(512)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_paths)\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = train_labels.shape[0]//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.525 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5625 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 56 steps\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - 58s 1s/step - loss: 1.4052 - categorical_accuracy: 0.4163\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 26s 464ms/step - loss: 0.9633 - categorical_accuracy: 0.6116\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 28s 505ms/step - loss: 0.5274 - categorical_accuracy: 0.8198\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 39s 689ms/step - loss: 0.4007 - categorical_accuracy: 0.8800\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 46s 829ms/step - loss: 0.3350 - categorical_accuracy: 0.8990\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2894 - categorical_accuracy: 0.9007\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.2264 - categorical_accuracy: 0.9308\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 45s 804ms/step - loss: 0.2093 - categorical_accuracy: 0.9369\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 46s 816ms/step - loss: 0.1768 - categorical_accuracy: 0.9403\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1560 - categorical_accuracy: 0.9436\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.1642 - categorical_accuracy: 0.9464\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 42s 743ms/step - loss: 0.1000 - categorical_accuracy: 0.9637\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 43s 775ms/step - loss: 0.0950 - categorical_accuracy: 0.9671\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1017 - categorical_accuracy: 0.9671\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0743 - categorical_accuracy: 0.9799\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 43s 769ms/step - loss: 0.0653 - categorical_accuracy: 0.9760\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1362 - categorical_accuracy: 0.9581\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 45s 807ms/step - loss: 0.0929 - categorical_accuracy: 0.9715\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 0.0618 - categorical_accuracy: 0.9799\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 49s 882ms/step - loss: 0.0592 - categorical_accuracy: 0.9816\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 47s 833ms/step - loss: 0.0464 - categorical_accuracy: 0.9866\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 50s 885ms/step - loss: 0.0441 - categorical_accuracy: 0.9860\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0720 - categorical_accuracy: 0.9771\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 45s 801ms/step - loss: 0.0260 - categorical_accuracy: 0.9900\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 0.0444 - categorical_accuracy: 0.9844\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 50s 886ms/step - loss: 0.0399 - categorical_accuracy: 0.9883\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 47s 843ms/step - loss: 0.0285 - categorical_accuracy: 0.9922\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 47s 847ms/step - loss: 0.0694 - categorical_accuracy: 0.9821\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 47s 838ms/step - loss: 0.0882 - categorical_accuracy: 0.9760\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.0414 - categorical_accuracy: 0.9833\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0485 - categorical_accuracy: 0.9872\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0375 - categorical_accuracy: 0.9888\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0856 - categorical_accuracy: 0.9732\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 46s 814ms/step - loss: 0.1032 - categorical_accuracy: 0.9693\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 45s 806ms/step - loss: 0.0882 - categorical_accuracy: 0.9732\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0539 - categorical_accuracy: 0.9838\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 43s 770ms/step - loss: 0.0424 - categorical_accuracy: 0.9860\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.0418 - categorical_accuracy: 0.9849\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 48s 851ms/step - loss: 0.0707 - categorical_accuracy: 0.9782\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 46s 817ms/step - loss: 0.0511 - categorical_accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23688487b48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b7 = tf.keras.Sequential([\n",
    "    efn.EfficientNetB7(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                       weights=\"imagenet\",\n",
    "                       include_top=False),\n",
    "    L.GlobalAveragePooling2D(),\n",
    "    L.Dense(nb_classes, activation=\"softmax\")\n",
    "])\n",
    "model_b7.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "model_b7.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch= STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "165527552/165527152 [==============================] - 6s 0us/step\n",
      "Train for 56 steps\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - 78s 1s/step - loss: 1.2818 - categorical_accuracy: 0.4643\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 41s 739ms/step - loss: 0.7149 - categorical_accuracy: 0.7355\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 45s 810ms/step - loss: 0.4756 - categorical_accuracy: 0.8343\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 45s 795ms/step - loss: 0.3396 - categorical_accuracy: 0.8839\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 44s 777ms/step - loss: 0.2856 - categorical_accuracy: 0.9001\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 41s 735ms/step - loss: 0.2405 - categorical_accuracy: 0.9213\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 47s 834ms/step - loss: 0.1869 - categorical_accuracy: 0.9442\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1506 - categorical_accuracy: 0.9481\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0968 - categorical_accuracy: 0.9626\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 45s 808ms/step - loss: 0.1398 - categorical_accuracy: 0.9537\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 45s 811ms/step - loss: 0.0883 - categorical_accuracy: 0.9710\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 47s 847ms/step - loss: 0.1017 - categorical_accuracy: 0.9682\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 45s 810ms/step - loss: 0.1131 - categorical_accuracy: 0.9609\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.0995 - categorical_accuracy: 0.9676\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 47s 842ms/step - loss: 0.0909 - categorical_accuracy: 0.9732\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 46s 817ms/step - loss: 0.0902 - categorical_accuracy: 0.9760\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0699 - categorical_accuracy: 0.9794\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0762 - categorical_accuracy: 0.9727\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 48s 856ms/step - loss: 0.0543 - categorical_accuracy: 0.9788\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.1067 - categorical_accuracy: 0.9693\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 40s 722ms/step - loss: 0.0753 - categorical_accuracy: 0.9766\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 43s 766ms/step - loss: 0.0371 - categorical_accuracy: 0.9883\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 43s 775ms/step - loss: 0.0656 - categorical_accuracy: 0.9794\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 40s 721ms/step - loss: 0.0754 - categorical_accuracy: 0.9760\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 40s 715ms/step - loss: 0.0677 - categorical_accuracy: 0.9805\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 42s 742ms/step - loss: 0.0354 - categorical_accuracy: 0.9883\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 40s 719ms/step - loss: 0.0383 - categorical_accuracy: 0.9877\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 40s 708ms/step - loss: 0.0619 - categorical_accuracy: 0.9799\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 40s 722ms/step - loss: 0.0454 - categorical_accuracy: 0.9872\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 40s 718ms/step - loss: 0.0530 - categorical_accuracy: 0.9816\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 40s 710ms/step - loss: 0.0872 - categorical_accuracy: 0.9738\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 40s 712ms/step - loss: 0.1037 - categorical_accuracy: 0.9710\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 40s 713ms/step - loss: 0.0740 - categorical_accuracy: 0.9771\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 40s 722ms/step - loss: 0.0390 - categorical_accuracy: 0.9900\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 40s 714ms/step - loss: 0.0522 - categorical_accuracy: 0.9883\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 42s 753ms/step - loss: 0.0233 - categorical_accuracy: 0.9916\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 39s 701ms/step - loss: 0.0428 - categorical_accuracy: 0.9900\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 43s 765ms/step - loss: 0.0499 - categorical_accuracy: 0.9849\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 40s 712ms/step - loss: 0.0264 - categorical_accuracy: 0.9916\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 39s 705ms/step - loss: 0.0165 - categorical_accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2370aa373c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b6 = tf.keras.Sequential([\n",
    "    efn.EfficientNetB6(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                       weights=\"imagenet\",\n",
    "                       include_top=False),\n",
    "    L.GlobalAveragePooling2D(),\n",
    "    L.Dense(nb_classes, activation=\"softmax\")\n",
    "])\n",
    "model_b6.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "model_b6.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch= STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234553344/234545216 [==============================] - 8s 0us/step\n",
      "Train for 56 steps\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - 65s 1s/step - loss: 1.3306 - categorical_accuracy: 0.4090\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 36s 644ms/step - loss: 1.0179 - categorical_accuracy: 0.5898\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 37s 655ms/step - loss: 0.7516 - categorical_accuracy: 0.7321\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 36s 649ms/step - loss: 0.5694 - categorical_accuracy: 0.8114\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 37s 657ms/step - loss: 0.5039 - categorical_accuracy: 0.8376\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 36s 643ms/step - loss: 0.4269 - categorical_accuracy: 0.8622\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 36s 641ms/step - loss: 0.3774 - categorical_accuracy: 0.8728\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 36s 650ms/step - loss: 0.3482 - categorical_accuracy: 0.8828\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 36s 651ms/step - loss: 0.3319 - categorical_accuracy: 0.8962\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 36s 640ms/step - loss: 0.2627 - categorical_accuracy: 0.9185\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 37s 659ms/step - loss: 0.2106 - categorical_accuracy: 0.9319\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 38s 676ms/step - loss: 0.2696 - categorical_accuracy: 0.9157\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 43s 760ms/step - loss: 0.2914 - categorical_accuracy: 0.9124\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 40s 706ms/step - loss: 0.2189 - categorical_accuracy: 0.9275\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 37s 662ms/step - loss: 0.2082 - categorical_accuracy: 0.9342\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 37s 662ms/step - loss: 0.1785 - categorical_accuracy: 0.9425\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 37s 659ms/step - loss: 0.1789 - categorical_accuracy: 0.9403\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 36s 644ms/step - loss: 0.1414 - categorical_accuracy: 0.9593\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 36s 646ms/step - loss: 0.1586 - categorical_accuracy: 0.9481\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 36s 649ms/step - loss: 0.1272 - categorical_accuracy: 0.9565\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 37s 658ms/step - loss: 0.1348 - categorical_accuracy: 0.9581\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 37s 653ms/step - loss: 0.1077 - categorical_accuracy: 0.9648\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 36s 651ms/step - loss: 0.1178 - categorical_accuracy: 0.9615\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 37s 656ms/step - loss: 0.0830 - categorical_accuracy: 0.9721\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 36s 651ms/step - loss: 0.0832 - categorical_accuracy: 0.9743\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 36s 643ms/step - loss: 0.0748 - categorical_accuracy: 0.9760\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 36s 652ms/step - loss: 0.0754 - categorical_accuracy: 0.9805\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 37s 656ms/step - loss: 0.0805 - categorical_accuracy: 0.9754\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 37s 659ms/step - loss: 0.0716 - categorical_accuracy: 0.9777\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 37s 654ms/step - loss: 0.0932 - categorical_accuracy: 0.9682\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 37s 656ms/step - loss: 0.0852 - categorical_accuracy: 0.9732\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 36s 641ms/step - loss: 0.0621 - categorical_accuracy: 0.9844\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 40s 712ms/step - loss: 0.0827 - categorical_accuracy: 0.9771\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 40s 710ms/step - loss: 0.1047 - categorical_accuracy: 0.9665\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 39s 694ms/step - loss: 0.0665 - categorical_accuracy: 0.9799\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 38s 674ms/step - loss: 0.0344 - categorical_accuracy: 0.9883\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 38s 672ms/step - loss: 0.0763 - categorical_accuracy: 0.9771\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 37s 654ms/step - loss: 0.0671 - categorical_accuracy: 0.9805\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 38s 673ms/step - loss: 0.0630 - categorical_accuracy: 0.9782\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 37s 665ms/step - loss: 0.0499 - categorical_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23742c90648>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model152v2 = tf.keras.Sequential([\n",
    "    ResNet152V2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                       weights=\"imagenet\",\n",
    "                       include_top=False),\n",
    "    L.GlobalAveragePooling2D(),\n",
    "    L.Dense(nb_classes, activation=\"softmax\")\n",
    "])\n",
    "model152v2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "model152v2.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch= STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 11s 0us/step\n",
      "Train for 56 steps\n",
      "Epoch 1/40\n",
      "56/56 [==============================] - 74s 1s/step - loss: 1.3414 - categorical_accuracy: 0.6166\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 38s 685ms/step - loss: 0.5862 - categorical_accuracy: 0.7874\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 39s 691ms/step - loss: 0.4399 - categorical_accuracy: 0.8599\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 41s 741ms/step - loss: 0.2977 - categorical_accuracy: 0.9090\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 38s 678ms/step - loss: 0.2699 - categorical_accuracy: 0.9208\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 77s 1s/step - loss: 0.2354 - categorical_accuracy: 0.9325\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 39s 700ms/step - loss: 0.1625 - categorical_accuracy: 0.9459\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 83s 1s/step - loss: 0.1487 - categorical_accuracy: 0.9481\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 85s 2s/step - loss: 0.1067 - categorical_accuracy: 0.9660\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 81s 1s/step - loss: 0.1299 - categorical_accuracy: 0.9626\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 83s 1s/step - loss: 0.0919 - categorical_accuracy: 0.9693\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 88s 2s/step - loss: 0.0990 - categorical_accuracy: 0.9693\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 81s 1s/step - loss: 0.1169 - categorical_accuracy: 0.9648\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 82s 1s/step - loss: 0.1213 - categorical_accuracy: 0.9632\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 32s 569ms/step - loss: 0.1494 - categorical_accuracy: 0.9593\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 22s 388ms/step - loss: 0.1061 - categorical_accuracy: 0.9688\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 27s 474ms/step - loss: 0.0856 - categorical_accuracy: 0.9754\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 41s 732ms/step - loss: 0.0627 - categorical_accuracy: 0.9771\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 41s 735ms/step - loss: 0.0565 - categorical_accuracy: 0.9816\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 39s 704ms/step - loss: 0.2186 - categorical_accuracy: 0.9375\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 39s 698ms/step - loss: 0.2263 - categorical_accuracy: 0.9263\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 40s 708ms/step - loss: 0.1446 - categorical_accuracy: 0.9537\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 39s 703ms/step - loss: 0.1538 - categorical_accuracy: 0.9475\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 40s 717ms/step - loss: 0.1389 - categorical_accuracy: 0.9609\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 39s 695ms/step - loss: 0.1335 - categorical_accuracy: 0.9671\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 42s 743ms/step - loss: 0.0862 - categorical_accuracy: 0.9721\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 41s 725ms/step - loss: 0.0667 - categorical_accuracy: 0.9827\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 38s 681ms/step - loss: 0.0311 - categorical_accuracy: 0.9883\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 41s 731ms/step - loss: 0.0335 - categorical_accuracy: 0.9911\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0276 - categorical_accuracy: 0.9944\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 41s 738ms/step - loss: 0.0521 - categorical_accuracy: 0.9844\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 39s 688ms/step - loss: 0.0399 - categorical_accuracy: 0.9860\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 39s 693ms/step - loss: 0.0156 - categorical_accuracy: 0.9955\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 39s 691ms/step - loss: 0.0283 - categorical_accuracy: 0.9939\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 39s 689ms/step - loss: 0.0302 - categorical_accuracy: 0.9916\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 40s 714ms/step - loss: 0.0160 - categorical_accuracy: 0.9939\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 39s 693ms/step - loss: 0.0311 - categorical_accuracy: 0.9894\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 39s 693ms/step - loss: 0.0264 - categorical_accuracy: 0.9894\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 39s 703ms/step - loss: 0.0372 - categorical_accuracy: 0.9872\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 39s 698ms/step - loss: 0.0280 - categorical_accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237663a3fc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelirv2 = tf.keras.Sequential([\n",
    "    InceptionResNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                       weights=\"imagenet\",\n",
    "                       include_top=False),\n",
    "    L.GlobalAveragePooling2D(),\n",
    "    L.Dense(nb_classes, activation=\"softmax\")\n",
    "])\n",
    "modelirv2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "modelirv2.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch= STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelicv3 = tf.keras.Sequential([\n",
    "#     InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "#                        weights=\"imagenet\",\n",
    "#                        include_top=False),\n",
    "#     L.GlobalAveragePooling2D(),\n",
    "#     L.Dense(nb_classes, activation=\"softmax\")\n",
    "# ])\n",
    "# modelicv3.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "# modelicv3.fit(\n",
    "#     train_dataset,\n",
    "#     steps_per_epoch= STEPS_PER_EPOCH,\n",
    "#     epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 49s 852ms/step\n",
      "57/57 [==============================] - 41s 714ms/step\n",
      "57/57 [==============================] - 38s 672ms/step\n",
      "57/57 [==============================] - 39s 686ms/step\n"
     ]
    }
   ],
   "source": [
    "opb7 = model_b7.predict(test_dataset, verbose=1)\n",
    "opb6 = model_b6.predict(test_dataset, verbose=1)\n",
    "op152v2 = model152v2.predict(test_dataset, verbose=1)\n",
    "opirv2 = modelirv2.predict(test_dataset, verbose=1)\n",
    "# opicv3 = modelicv3.predict(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.995562</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.994712</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.996550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id   healthy  multiple_diseases      rust      scab\n",
       "0   Test_0  0.000511           0.003515  0.995562  0.000412\n",
       "1   Test_1  0.005254           0.000012  0.994712  0.000022\n",
       "2   Test_2  0.003049           0.000369  0.000032  0.996550\n",
       "3   Test_3  0.999862           0.000070  0.000003  0.000065\n",
       "4   Test_4  0.000011           0.000041  0.999942  0.000006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av = (2*opb7 + opb6 + op152v2 + opirv2)/5\n",
    "submission_df.loc[:, 'healthy':] = av\n",
    "submission_df.to_csv('submission_extreme_ensemble.csv', index=False)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
